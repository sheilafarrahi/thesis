{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107f76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "from numpy import mean, var\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dae3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configurations for number of samples and moments\n",
    "s_size = 10\n",
    "nr_sample = 2\n",
    "nr_moments = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f37988",
   "metadata": {},
   "source": [
    "## Bounded intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8efec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples from distributions with bounded intervals\n",
    "from scipy.stats import arcsine, beta, powerlaw, trapezoid, triang, uniform\n",
    "\n",
    "r_arcsine = arcsine.rvs(size=(nr_sample, s_size),random_state=10)\n",
    "r_beta = beta.rvs(1,2, size=(nr_sample, s_size), random_state=10)\n",
    "r_powerlaw = powerlaw.rvs(0.3, size=(nr_sample, s_size),random_state=10)\n",
    "r_trapezoid = trapezoid.rvs(0.3, 0.8, size=(nr_sample, s_size), random_state=10)\n",
    "r_traing = triang.rvs(0.3, size=(nr_sample, s_size),random_state=10)\n",
    "r_uniform = uniform.rvs(size=(nr_sample, s_size),random_state=10)\n",
    "\n",
    "bounded_c_rvs = [r_arcsine, r_beta, r_powerlaw, r_trapezoid, r_traing, r_uniform]\n",
    "bounded_c_dists_names = ['arcsine', 'beta', 'powerlaw', 'trapezoid', 'triangular', 'uniform']\n",
    "\n",
    "bounded_c = pd.DataFrame()\n",
    "\n",
    "# parameter moment is the central mean, so I used mean() for n=1\n",
    "for i in range(len(bounded_c_rvs)):\n",
    "    m = np.zeros((nr_moments,nr_sample))\n",
    "    m[0,]  = mean(bounded_c_rvs[i], axis = 1)\n",
    "    for n in range(2,nr_moments+1):\n",
    "        m[n-1,] = moment(bounded_c_rvs[i], n, axis=1)\n",
    "        \n",
    "    df_temp = pd.DataFrame(np.transpose(m))\n",
    "    df_temp['dist'] = bounded_c_dists_names[i]\n",
    "\n",
    "    bounded_c=pd.concat([bounded_c, df_temp], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7c420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c138a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_moments_df(r, ms, s):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(r)):\n",
    "        m = np.zeros((ms,s))\n",
    "        m[0,]  = mean(r[i], axis = 1)\n",
    "        for n in range(2,ms+1):\n",
    "            m[n-1,] = moment(r[i], n, axis=1)\n",
    "\n",
    "        df_temp = pd.DataFrame(np.transpose(m))\n",
    "        df_temp['dist'] = bounded_c_dists_names[i]\n",
    "\n",
    "        df=pd.concat([df, df_temp], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1db5c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.409759</td>\n",
       "      <td>0.133492</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>arcsine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.668998</td>\n",
       "      <td>0.101442</td>\n",
       "      <td>-0.032035</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>-0.014994</td>\n",
       "      <td>arcsine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305954</td>\n",
       "      <td>0.040414</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.314615</td>\n",
       "      <td>0.070845</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.153481</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>powerlaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.337140</td>\n",
       "      <td>0.075661</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>powerlaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.449863</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.608003</td>\n",
       "      <td>0.055204</td>\n",
       "      <td>-0.015707</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>-0.005645</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.364264</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>triangular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.508485</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>-0.002044</td>\n",
       "      <td>triangular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.411387</td>\n",
       "      <td>0.081827</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.622602</td>\n",
       "      <td>0.075929</td>\n",
       "      <td>-0.020353</td>\n",
       "      <td>0.017965</td>\n",
       "      <td>-0.008813</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4        dist\n",
       "0   0.409759  0.133492  0.008527  0.021801  0.003055     arcsine\n",
       "1   0.668998  0.101442 -0.032035  0.027668 -0.014994     arcsine\n",
       "2   0.305954  0.040414  0.000272  0.002902  0.000104        beta\n",
       "3   0.314615  0.070845  0.014492  0.012941  0.005379        beta\n",
       "4   0.153481  0.030561  0.002921  0.001419  0.000253    powerlaw\n",
       "5   0.337140  0.075661  0.012620  0.012758  0.004036    powerlaw\n",
       "6   0.449863  0.051348 -0.000562  0.003829 -0.000224   trapezoid\n",
       "7   0.608003  0.055204 -0.015707  0.011510 -0.005645   trapezoid\n",
       "8   0.364264  0.033898  0.000006  0.001717 -0.000048  triangular\n",
       "9   0.508485  0.046109 -0.006861  0.006627 -0.002044  triangular\n",
       "10  0.411387  0.081827  0.001550  0.008801  0.000203     uniform\n",
       "11  0.622602  0.075929 -0.020353  0.017965 -0.008813     uniform"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_moments_df(bounded_c_rvs, 5, nr_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42cda197",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rvs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ec7e988ac396>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnr_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stepfilled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdists_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rvs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "nrow = 2\n",
    "ncol = 3\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize =(15,10))\n",
    "\n",
    "for row in range(nrow):\n",
    "    for col in range(ncol):\n",
    "        for i in range(nr_sample):\n",
    "            ax[row,col].hist(rvs[row*3+col][i,:], density=True, bins='auto', histtype='stepfilled', alpha=0.1)\n",
    "            ax[row,col].set_title(dists_names[row*3+col])\n",
    "            ax[row,col].set_xlim(0,1)\n",
    "            ax[row,col].set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27796a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "X = bounded_c.drop('dist', axis=1)\n",
    "\n",
    "# Scaling data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# response variable\n",
    "y = bounded_c['dist']\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size= 0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f149",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db1c4ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a45c6fc92bbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0moptimal_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moptimal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    805\u001b[0m                                                        **fit_and_score_kwargs)\n\u001b[0;32m    806\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcand_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                                    (split_idx, (train, test)) in product(\n\u001b[0m\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                                    enumerate(cv.split(X, y, groups))))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0mmin_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0my_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[0m\u001b[0;32m    663\u001b[0m                              \u001b[1;34m\" number of members in each class.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                              % (self.n_splits))\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "# find the best parameters\n",
    "param_grid = [\n",
    "    {'C':np.logspace(0.1, 50, 20),\n",
    "     'gamma':np.logspace(0.001, 10, 20), \n",
    "     'kernel':['rbf']},\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(SVC(), param_grid,cv=5, verbose=0)\n",
    "\n",
    "optimal_params.fit(X_train, y_train)\n",
    "print(optimal_params.best_params_)\n",
    "\n",
    "c = optimal_params.best_params_['C']\n",
    "g = optimal_params.best_params_['gamma']\n",
    "\n",
    "clf_svm = SVC(random_state=10, C=c, gamma=g)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(c_matrix, display_labels=clf_svm.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, colorbar=False, xticks_rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "scores = cross_val_score(clf_svm, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473f488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef25289",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea8f5768",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e129864a5a89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0moptimal_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0moptimal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_y\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             residual = loss.negative_gradient(y, raw_predictions_copy, k=k,\n\u001b[0m\u001b[0;32m    192\u001b[0m                                               sample_weight=sample_weight)\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[1;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \"\"\"\n\u001b[0;32m    719\u001b[0m         return y - np.nan_to_num(np.exp(raw_predictions[:, k] -\n\u001b[1;32m--> 720\u001b[1;33m                                         logsumexp(raw_predictions, axis=1)))\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\special\\_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0ma_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2731\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m     \"\"\"\n\u001b[1;32m-> 2733\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2734\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators':[100, 500, 750],\n",
    "     'learning_rate':[0.001, 0.01, 0.1], \n",
    "     'max_depth':[3, 5, 8]},\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, verbose=0)\n",
    "\n",
    "optimal_params.fit(X_train, y_train)\n",
    "print(optimal_params.best_params_)\n",
    "\n",
    "n_estimators = optimal_params.best_params_['n_estimators']\n",
    "l_rate = optimal_params.best_params_['learning_rate']\n",
    "m_depth = optimal_params.best_params_['max_depth']\n",
    "\n",
    "clf_gbm = GradientBoostingClassifier(n_estimators=n_estimators,\n",
    "                                     learning_rate=l_rate,\n",
    "                                     max_depth=m_depth)\n",
    "                                     \n",
    "clf_gbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_gbm.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(c_matrix, display_labels=clf_gbm.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, colorbar=False, xticks_rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "scores = cross_val_score(clf_gbm, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9cccc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples from different distributions\n",
    "# exponential\n",
    "ex_lambda = 3.5\n",
    "r_expon = expon.rvs(size=(nr_sample,s_size), scale = 1/ex_lambda, random_state=10)\n",
    "\n",
    "# gamma\n",
    "alpha = 1\n",
    "r_gamma = gamma.rvs(alpha, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# chi\n",
    "d_f = 25\n",
    "r_chi = chi.rvs(d_f, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# lognormal\n",
    "s = 1\n",
    "r_lognorm = lognorm.rvs(s, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# beta\n",
    "a, b = 0.5, 0.5\n",
    "r_beta = beta.rvs(a, b, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# trapezoind\n",
    "c, d = 0.3, 0.4\n",
    "r_trapezoid = trapezoid.rvs(c, d, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# exponpow\n",
    "b = 5\n",
    "r_exponpow = exponpow.rvs(b, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# normal\n",
    "r_norm = norm.rvs(size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# cosine\n",
    "r_cosine = cosine.rvs(size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# cauchy\n",
    "r_cauchy = cauchy.rvs(size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# poisson\n",
    "mu = 10\n",
    "r_pois = poisson.rvs(mu, size=(nr_sample, s_size), random_state=10)\n",
    "\n",
    "# hypergeom\n",
    "M, n, N = 20, 7, 12\n",
    "r_hypergeom =  hypergeom.rvs(M, n, N, size=(nr_sample, s_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "387221f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = [r_expon, r_gamma, r_lognorm, r_beta, r_trapezoid, r_norm, r_hypergeom, r_exponpow, r_pois]\n",
    "dists_names = ['exponential', 'gamma', 'lognormal','beta', 'trapezoid', 'normal','hyper_geometric',\n",
    "               'exponential_power','poisson']\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# parameter moment is the central mean, so I used mean() for n=1\n",
    "for i in range(len(rvs)):\n",
    "    m = np.zeros((nr_moments,nr_sample))\n",
    "    m[0,]  = mean(rvs[i], axis = 1)\n",
    "    for n in range(2,nr_moments+1):\n",
    "        m[n-1,] = moment(rvs[i], n, axis=1)\n",
    "        \n",
    "    df_temp = pd.DataFrame(np.transpose(m))\n",
    "    df_temp['dist'] = dists_names[i]\n",
    "\n",
    "    df_final=pd.concat([df_final, df_temp], ignore_index=True)\n",
    "    \n",
    "# write to csv\n",
    "df_final.to_csv('moments.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7927b037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "nrow = 2\n",
    "ncol = 3\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize =(15,10))\n",
    "\n",
    "for row in range(nrow):\n",
    "    for col in range(ncol):\n",
    "        for i in range(nr_sample):\n",
    "            ax[row,col].hist(rvs[row*3+col][i,:], density=True, bins='auto', histtype='stepfilled', alpha=0.1)\n",
    "            ax[row,col].set_title(dists_names[row*3+col])\n",
    "            ax[row,col].set_xlim(0,1)\n",
    "            ax[row,col].set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "455bc86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472515</td>\n",
       "      <td>0.215198</td>\n",
       "      <td>0.214862</td>\n",
       "      <td>0.489494</td>\n",
       "      <td>1.208886</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501796</td>\n",
       "      <td>0.249386</td>\n",
       "      <td>0.232755</td>\n",
       "      <td>0.492877</td>\n",
       "      <td>1.031487</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467825</td>\n",
       "      <td>0.222402</td>\n",
       "      <td>0.231120</td>\n",
       "      <td>0.568067</td>\n",
       "      <td>1.641068</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525629</td>\n",
       "      <td>0.245039</td>\n",
       "      <td>0.205732</td>\n",
       "      <td>0.395267</td>\n",
       "      <td>0.715290</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.499297</td>\n",
       "      <td>0.248144</td>\n",
       "      <td>0.230677</td>\n",
       "      <td>0.460638</td>\n",
       "      <td>0.888709</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         dist\n",
       "0  0.472515  0.215198  0.214862  0.489494  1.208886  exponential\n",
       "1  0.501796  0.249386  0.232755  0.492877  1.031487  exponential\n",
       "2  0.467825  0.222402  0.231120  0.568067  1.641068  exponential\n",
       "3  0.525629  0.245039  0.205732  0.395267  0.715290  exponential\n",
       "4  0.499297  0.248144  0.230677  0.460638  0.888709  exponential"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0566dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278477</td>\n",
       "      <td>0.076947</td>\n",
       "      <td>0.039534</td>\n",
       "      <td>0.044959</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294094</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>0.069032</td>\n",
       "      <td>0.132611</td>\n",
       "      <td>0.306223</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273634</td>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.043785</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.053657</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.277206</td>\n",
       "      <td>0.074974</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>0.046933</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265108</td>\n",
       "      <td>0.070054</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.040880</td>\n",
       "      <td>0.045851</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.287305</td>\n",
       "      <td>0.086687</td>\n",
       "      <td>0.052420</td>\n",
       "      <td>0.071863</td>\n",
       "      <td>0.110257</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.270158</td>\n",
       "      <td>0.083211</td>\n",
       "      <td>0.061479</td>\n",
       "      <td>0.098035</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.271438</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>0.041453</td>\n",
       "      <td>0.052457</td>\n",
       "      <td>0.070142</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.279658</td>\n",
       "      <td>0.087117</td>\n",
       "      <td>0.066054</td>\n",
       "      <td>0.102184</td>\n",
       "      <td>0.170926</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.297224</td>\n",
       "      <td>0.087612</td>\n",
       "      <td>0.055138</td>\n",
       "      <td>0.075090</td>\n",
       "      <td>0.105865</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.282413</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.038688</td>\n",
       "      <td>0.044002</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.281632</td>\n",
       "      <td>0.068224</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.303073</td>\n",
       "      <td>0.094398</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.067330</td>\n",
       "      <td>0.081840</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.285709</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.041512</td>\n",
       "      <td>0.055282</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.293362</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>0.046954</td>\n",
       "      <td>0.048631</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.271413</td>\n",
       "      <td>0.073062</td>\n",
       "      <td>0.033895</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.277423</td>\n",
       "      <td>0.077938</td>\n",
       "      <td>0.038860</td>\n",
       "      <td>0.041798</td>\n",
       "      <td>0.043272</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.291878</td>\n",
       "      <td>0.091614</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.076286</td>\n",
       "      <td>0.112284</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.292739</td>\n",
       "      <td>0.088436</td>\n",
       "      <td>0.055893</td>\n",
       "      <td>0.075453</td>\n",
       "      <td>0.106315</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.287753</td>\n",
       "      <td>0.076151</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>0.038538</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.280747</td>\n",
       "      <td>0.083716</td>\n",
       "      <td>0.054285</td>\n",
       "      <td>0.081420</td>\n",
       "      <td>0.140376</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.289409</td>\n",
       "      <td>0.079826</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>0.045969</td>\n",
       "      <td>0.048981</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.290112</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>0.042643</td>\n",
       "      <td>0.050522</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.296659</td>\n",
       "      <td>0.093434</td>\n",
       "      <td>0.066137</td>\n",
       "      <td>0.099226</td>\n",
       "      <td>0.159751</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.289576</td>\n",
       "      <td>0.090444</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.063077</td>\n",
       "      <td>0.072860</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.974669</td>\n",
       "      <td>0.942605</td>\n",
       "      <td>1.695013</td>\n",
       "      <td>6.746629</td>\n",
       "      <td>26.284591</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.029327</td>\n",
       "      <td>1.113531</td>\n",
       "      <td>2.959749</td>\n",
       "      <td>19.899957</td>\n",
       "      <td>160.834152</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.957717</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>1.877276</td>\n",
       "      <td>7.313499</td>\n",
       "      <td>28.181585</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.970221</td>\n",
       "      <td>0.918433</td>\n",
       "      <td>1.611387</td>\n",
       "      <td>6.271201</td>\n",
       "      <td>24.650097</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.927878</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>1.576605</td>\n",
       "      <td>6.134503</td>\n",
       "      <td>24.082002</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.005568</td>\n",
       "      <td>1.061911</td>\n",
       "      <td>2.247510</td>\n",
       "      <td>10.783912</td>\n",
       "      <td>57.909049</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.945553</td>\n",
       "      <td>1.019337</td>\n",
       "      <td>2.635931</td>\n",
       "      <td>14.711318</td>\n",
       "      <td>92.212898</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.950032</td>\n",
       "      <td>0.909347</td>\n",
       "      <td>1.777301</td>\n",
       "      <td>7.871832</td>\n",
       "      <td>36.839676</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.978803</td>\n",
       "      <td>1.067185</td>\n",
       "      <td>2.832069</td>\n",
       "      <td>15.333930</td>\n",
       "      <td>89.773692</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.040283</td>\n",
       "      <td>1.073242</td>\n",
       "      <td>2.364030</td>\n",
       "      <td>11.268170</td>\n",
       "      <td>55.602299</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.988447</td>\n",
       "      <td>0.960113</td>\n",
       "      <td>1.658757</td>\n",
       "      <td>6.603118</td>\n",
       "      <td>25.643394</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.985712</td>\n",
       "      <td>0.835746</td>\n",
       "      <td>1.274990</td>\n",
       "      <td>4.774917</td>\n",
       "      <td>17.139402</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.060756</td>\n",
       "      <td>1.156375</td>\n",
       "      <td>2.326652</td>\n",
       "      <td>10.103728</td>\n",
       "      <td>42.983892</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.941229</td>\n",
       "      <td>1.779812</td>\n",
       "      <td>8.295732</td>\n",
       "      <td>41.299443</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.026769</td>\n",
       "      <td>1.013868</td>\n",
       "      <td>1.834373</td>\n",
       "      <td>7.045969</td>\n",
       "      <td>25.542083</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.949944</td>\n",
       "      <td>0.895004</td>\n",
       "      <td>1.453244</td>\n",
       "      <td>5.016631</td>\n",
       "      <td>16.300536</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.970980</td>\n",
       "      <td>0.954746</td>\n",
       "      <td>1.666106</td>\n",
       "      <td>6.272258</td>\n",
       "      <td>22.727139</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.021574</td>\n",
       "      <td>1.122276</td>\n",
       "      <td>2.408134</td>\n",
       "      <td>11.447675</td>\n",
       "      <td>58.973541</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.024586</td>\n",
       "      <td>1.083343</td>\n",
       "      <td>2.396400</td>\n",
       "      <td>11.322599</td>\n",
       "      <td>55.838803</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.007134</td>\n",
       "      <td>0.932847</td>\n",
       "      <td>1.527965</td>\n",
       "      <td>5.783078</td>\n",
       "      <td>20.945915</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.982615</td>\n",
       "      <td>1.025521</td>\n",
       "      <td>2.327461</td>\n",
       "      <td>12.218086</td>\n",
       "      <td>73.728175</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.012932</td>\n",
       "      <td>0.977864</td>\n",
       "      <td>1.778843</td>\n",
       "      <td>6.898218</td>\n",
       "      <td>25.725767</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.015390</td>\n",
       "      <td>0.993290</td>\n",
       "      <td>1.828333</td>\n",
       "      <td>7.581510</td>\n",
       "      <td>31.591863</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.038308</td>\n",
       "      <td>1.144565</td>\n",
       "      <td>2.835612</td>\n",
       "      <td>14.890162</td>\n",
       "      <td>83.903993</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.013516</td>\n",
       "      <td>1.107944</td>\n",
       "      <td>2.284496</td>\n",
       "      <td>9.465561</td>\n",
       "      <td>38.267282</td>\n",
       "      <td>gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.531265</td>\n",
       "      <td>3.136374</td>\n",
       "      <td>19.029185</td>\n",
       "      <td>184.498703</td>\n",
       "      <td>1916.780787</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.596649</td>\n",
       "      <td>3.373854</td>\n",
       "      <td>18.989939</td>\n",
       "      <td>180.824257</td>\n",
       "      <td>1888.931844</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.605864</td>\n",
       "      <td>4.400015</td>\n",
       "      <td>60.698859</td>\n",
       "      <td>1716.165665</td>\n",
       "      <td>56721.369871</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.575350</td>\n",
       "      <td>4.175707</td>\n",
       "      <td>46.405978</td>\n",
       "      <td>1029.942996</td>\n",
       "      <td>27319.260786</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.574421</td>\n",
       "      <td>3.727588</td>\n",
       "      <td>27.487909</td>\n",
       "      <td>347.650632</td>\n",
       "      <td>5025.101467</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.601411</td>\n",
       "      <td>4.632585</td>\n",
       "      <td>53.835993</td>\n",
       "      <td>995.655436</td>\n",
       "      <td>20118.320040</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.714511</td>\n",
       "      <td>4.884108</td>\n",
       "      <td>45.757692</td>\n",
       "      <td>716.122340</td>\n",
       "      <td>12555.631380</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.738949</td>\n",
       "      <td>5.382786</td>\n",
       "      <td>67.721896</td>\n",
       "      <td>1621.835290</td>\n",
       "      <td>47003.940030</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.734348</td>\n",
       "      <td>4.988502</td>\n",
       "      <td>75.833386</td>\n",
       "      <td>2357.049707</td>\n",
       "      <td>85180.100002</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.670441</td>\n",
       "      <td>4.715232</td>\n",
       "      <td>66.496558</td>\n",
       "      <td>1623.891831</td>\n",
       "      <td>44502.978053</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.639070</td>\n",
       "      <td>3.748684</td>\n",
       "      <td>27.685409</td>\n",
       "      <td>355.760489</td>\n",
       "      <td>5037.097591</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.654432</td>\n",
       "      <td>3.688545</td>\n",
       "      <td>18.740236</td>\n",
       "      <td>154.228645</td>\n",
       "      <td>1303.854821</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.657732</td>\n",
       "      <td>4.268721</td>\n",
       "      <td>33.188316</td>\n",
       "      <td>469.999742</td>\n",
       "      <td>8062.727845</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.589619</td>\n",
       "      <td>3.994325</td>\n",
       "      <td>45.075532</td>\n",
       "      <td>1037.232649</td>\n",
       "      <td>28539.720619</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.654485</td>\n",
       "      <td>5.107409</td>\n",
       "      <td>63.084131</td>\n",
       "      <td>1314.861141</td>\n",
       "      <td>31380.434438</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.666209</td>\n",
       "      <td>5.966266</td>\n",
       "      <td>89.396587</td>\n",
       "      <td>2160.488402</td>\n",
       "      <td>58525.102877</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.674035</td>\n",
       "      <td>4.282708</td>\n",
       "      <td>32.377782</td>\n",
       "      <td>391.455121</td>\n",
       "      <td>5141.682996</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.597441</td>\n",
       "      <td>3.172705</td>\n",
       "      <td>18.328881</td>\n",
       "      <td>200.084300</td>\n",
       "      <td>2522.157878</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.693633</td>\n",
       "      <td>4.647290</td>\n",
       "      <td>48.139257</td>\n",
       "      <td>968.165487</td>\n",
       "      <td>23419.823642</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.505290</td>\n",
       "      <td>2.999431</td>\n",
       "      <td>19.294948</td>\n",
       "      <td>215.857402</td>\n",
       "      <td>2677.618610</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.751610</td>\n",
       "      <td>5.430262</td>\n",
       "      <td>47.804928</td>\n",
       "      <td>658.631324</td>\n",
       "      <td>9903.366135</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.592525</td>\n",
       "      <td>3.755191</td>\n",
       "      <td>25.118665</td>\n",
       "      <td>299.200480</td>\n",
       "      <td>4186.720006</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.589577</td>\n",
       "      <td>4.257870</td>\n",
       "      <td>59.878736</td>\n",
       "      <td>1661.876101</td>\n",
       "      <td>53787.767706</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.710450</td>\n",
       "      <td>4.661754</td>\n",
       "      <td>39.346754</td>\n",
       "      <td>580.409580</td>\n",
       "      <td>9913.412009</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.472298</td>\n",
       "      <td>2.497811</td>\n",
       "      <td>14.727903</td>\n",
       "      <td>177.173520</td>\n",
       "      <td>2516.658829</td>\n",
       "      <td>lognormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.508290</td>\n",
       "      <td>0.129629</td>\n",
       "      <td>-0.001551</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.499712</td>\n",
       "      <td>0.121832</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.495582</td>\n",
       "      <td>0.130833</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.511882</td>\n",
       "      <td>0.123728</td>\n",
       "      <td>-0.001812</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.505809</td>\n",
       "      <td>0.127109</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>0.024188</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.492339</td>\n",
       "      <td>0.126515</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.515454</td>\n",
       "      <td>0.130078</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.518054</td>\n",
       "      <td>0.120324</td>\n",
       "      <td>-0.002152</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.495548</td>\n",
       "      <td>0.123001</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.023095</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.128227</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.513482</td>\n",
       "      <td>0.123430</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>0.023198</td>\n",
       "      <td>-0.000849</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.523421</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>-0.003378</td>\n",
       "      <td>0.023182</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.504862</td>\n",
       "      <td>0.130860</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>0.024663</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.503063</td>\n",
       "      <td>0.125816</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.501392</td>\n",
       "      <td>0.121268</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>0.022390</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.497111</td>\n",
       "      <td>0.120115</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.504181</td>\n",
       "      <td>0.122514</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.497931</td>\n",
       "      <td>0.123217</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.529533</td>\n",
       "      <td>0.125682</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>-0.002126</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.504727</td>\n",
       "      <td>0.126001</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.502480</td>\n",
       "      <td>0.121207</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.022377</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.513662</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>-0.002427</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.505320</td>\n",
       "      <td>0.124370</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>0.023665</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.497222</td>\n",
       "      <td>0.120658</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.512487</td>\n",
       "      <td>0.131533</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>-0.000742</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.439291</td>\n",
       "      <td>0.044111</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.449721</td>\n",
       "      <td>0.045178</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.431187</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.440386</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.431497</td>\n",
       "      <td>0.040952</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.443633</td>\n",
       "      <td>0.045272</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.429884</td>\n",
       "      <td>0.043785</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.435286</td>\n",
       "      <td>0.042357</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.439057</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.453618</td>\n",
       "      <td>0.044235</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.441032</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.446689</td>\n",
       "      <td>0.042243</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.453911</td>\n",
       "      <td>0.047349</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.446131</td>\n",
       "      <td>0.044291</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.451895</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.434921</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.437788</td>\n",
       "      <td>0.044246</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.444495</td>\n",
       "      <td>0.047147</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.450446</td>\n",
       "      <td>0.043327</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.043242</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.439414</td>\n",
       "      <td>0.044369</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.450530</td>\n",
       "      <td>0.042344</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.449246</td>\n",
       "      <td>0.044003</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.451891</td>\n",
       "      <td>0.044086</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.444509</td>\n",
       "      <td>0.045233</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>trapezoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.879765</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>2.393398</td>\n",
       "      <td>-0.137235</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-0.011092</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>-0.058273</td>\n",
       "      <td>2.786129</td>\n",
       "      <td>-0.498211</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-0.021054</td>\n",
       "      <td>1.008537</td>\n",
       "      <td>-0.060422</td>\n",
       "      <td>2.985959</td>\n",
       "      <td>-0.197113</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-0.057498</td>\n",
       "      <td>1.031559</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>2.963175</td>\n",
       "      <td>0.312670</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-0.039038</td>\n",
       "      <td>1.003398</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>2.978564</td>\n",
       "      <td>-0.305131</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-0.004476</td>\n",
       "      <td>0.908281</td>\n",
       "      <td>0.104680</td>\n",
       "      <td>2.574936</td>\n",
       "      <td>0.897907</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.023742</td>\n",
       "      <td>1.041997</td>\n",
       "      <td>-0.034840</td>\n",
       "      <td>3.293245</td>\n",
       "      <td>-0.487705</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.993579</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>3.040081</td>\n",
       "      <td>0.260338</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.077557</td>\n",
       "      <td>0.960866</td>\n",
       "      <td>-0.066598</td>\n",
       "      <td>2.799230</td>\n",
       "      <td>-0.329110</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.048050</td>\n",
       "      <td>0.960096</td>\n",
       "      <td>-0.158853</td>\n",
       "      <td>2.903149</td>\n",
       "      <td>-0.683796</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.029131</td>\n",
       "      <td>0.943824</td>\n",
       "      <td>-0.026802</td>\n",
       "      <td>2.611996</td>\n",
       "      <td>-0.174299</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.016721</td>\n",
       "      <td>1.102892</td>\n",
       "      <td>-0.145662</td>\n",
       "      <td>3.517307</td>\n",
       "      <td>-1.812149</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-0.002597</td>\n",
       "      <td>1.006196</td>\n",
       "      <td>0.094467</td>\n",
       "      <td>2.851681</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-0.012805</td>\n",
       "      <td>0.965703</td>\n",
       "      <td>-0.044563</td>\n",
       "      <td>2.777876</td>\n",
       "      <td>-0.164021</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-0.021255</td>\n",
       "      <td>1.069079</td>\n",
       "      <td>-0.097764</td>\n",
       "      <td>3.521419</td>\n",
       "      <td>-0.651782</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.020236</td>\n",
       "      <td>1.020565</td>\n",
       "      <td>0.088318</td>\n",
       "      <td>3.284959</td>\n",
       "      <td>0.732796</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.013738</td>\n",
       "      <td>1.023779</td>\n",
       "      <td>-0.059434</td>\n",
       "      <td>3.149239</td>\n",
       "      <td>-0.605717</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>-0.200003</td>\n",
       "      <td>3.079174</td>\n",
       "      <td>-2.318946</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.016752</td>\n",
       "      <td>1.037377</td>\n",
       "      <td>-0.017003</td>\n",
       "      <td>3.045774</td>\n",
       "      <td>0.051260</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-0.051274</td>\n",
       "      <td>0.966770</td>\n",
       "      <td>-0.154680</td>\n",
       "      <td>2.840479</td>\n",
       "      <td>-1.288667</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.012444</td>\n",
       "      <td>1.075475</td>\n",
       "      <td>0.123754</td>\n",
       "      <td>3.309352</td>\n",
       "      <td>0.905070</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.040144</td>\n",
       "      <td>1.024431</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>3.057967</td>\n",
       "      <td>-0.355783</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.008138</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>-0.035908</td>\n",
       "      <td>2.714124</td>\n",
       "      <td>-0.205872</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.025850</td>\n",
       "      <td>1.013246</td>\n",
       "      <td>0.083868</td>\n",
       "      <td>2.888145</td>\n",
       "      <td>0.590343</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.032585</td>\n",
       "      <td>0.882453</td>\n",
       "      <td>-0.146300</td>\n",
       "      <td>2.440372</td>\n",
       "      <td>-1.724633</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>4.185000</td>\n",
       "      <td>1.130775</td>\n",
       "      <td>-0.130912</td>\n",
       "      <td>3.536499</td>\n",
       "      <td>-1.043270</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4.142000</td>\n",
       "      <td>1.155836</td>\n",
       "      <td>-0.071249</td>\n",
       "      <td>3.872225</td>\n",
       "      <td>-0.856066</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>4.214000</td>\n",
       "      <td>1.082204</td>\n",
       "      <td>0.085425</td>\n",
       "      <td>3.107416</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>4.197000</td>\n",
       "      <td>1.094191</td>\n",
       "      <td>-0.259312</td>\n",
       "      <td>3.877045</td>\n",
       "      <td>-3.215205</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>4.166000</td>\n",
       "      <td>1.250444</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>4.362013</td>\n",
       "      <td>-0.390337</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>4.267000</td>\n",
       "      <td>1.145711</td>\n",
       "      <td>0.026251</td>\n",
       "      <td>3.621822</td>\n",
       "      <td>0.113720</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>4.225000</td>\n",
       "      <td>1.100375</td>\n",
       "      <td>-0.187144</td>\n",
       "      <td>3.466628</td>\n",
       "      <td>-1.876131</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>4.175000</td>\n",
       "      <td>1.182375</td>\n",
       "      <td>-0.115106</td>\n",
       "      <td>4.003375</td>\n",
       "      <td>-0.836234</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>4.175000</td>\n",
       "      <td>1.232375</td>\n",
       "      <td>-0.105356</td>\n",
       "      <td>3.893363</td>\n",
       "      <td>-1.045639</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4.244000</td>\n",
       "      <td>1.070464</td>\n",
       "      <td>-0.170106</td>\n",
       "      <td>3.406092</td>\n",
       "      <td>-1.446527</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4.206000</td>\n",
       "      <td>1.145564</td>\n",
       "      <td>-0.126700</td>\n",
       "      <td>3.662921</td>\n",
       "      <td>-0.853557</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>4.214000</td>\n",
       "      <td>1.132204</td>\n",
       "      <td>-0.162675</td>\n",
       "      <td>3.788050</td>\n",
       "      <td>-1.716124</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>4.207000</td>\n",
       "      <td>1.126151</td>\n",
       "      <td>-0.033210</td>\n",
       "      <td>3.521135</td>\n",
       "      <td>-0.583411</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.132000</td>\n",
       "      <td>-0.097200</td>\n",
       "      <td>3.484480</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4.154000</td>\n",
       "      <td>1.058284</td>\n",
       "      <td>-0.032579</td>\n",
       "      <td>3.194917</td>\n",
       "      <td>-0.327097</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>4.206000</td>\n",
       "      <td>1.133564</td>\n",
       "      <td>-0.203284</td>\n",
       "      <td>3.789082</td>\n",
       "      <td>-2.209954</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4.168000</td>\n",
       "      <td>1.221776</td>\n",
       "      <td>0.015483</td>\n",
       "      <td>4.247898</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>4.144000</td>\n",
       "      <td>1.141264</td>\n",
       "      <td>0.145988</td>\n",
       "      <td>3.563489</td>\n",
       "      <td>1.323876</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>4.155000</td>\n",
       "      <td>1.214975</td>\n",
       "      <td>-0.125687</td>\n",
       "      <td>4.261210</td>\n",
       "      <td>-1.962575</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>4.237000</td>\n",
       "      <td>1.178831</td>\n",
       "      <td>-0.056461</td>\n",
       "      <td>3.588087</td>\n",
       "      <td>-0.510844</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>4.194000</td>\n",
       "      <td>1.166364</td>\n",
       "      <td>-0.084125</td>\n",
       "      <td>3.812481</td>\n",
       "      <td>-0.677881</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>4.101000</td>\n",
       "      <td>1.100799</td>\n",
       "      <td>-0.041572</td>\n",
       "      <td>3.556316</td>\n",
       "      <td>-1.222051</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>4.219000</td>\n",
       "      <td>1.155039</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>4.264374</td>\n",
       "      <td>0.281148</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>4.221000</td>\n",
       "      <td>1.176159</td>\n",
       "      <td>-0.041587</td>\n",
       "      <td>3.914709</td>\n",
       "      <td>-0.611922</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>4.239000</td>\n",
       "      <td>1.103879</td>\n",
       "      <td>-0.020133</td>\n",
       "      <td>3.594656</td>\n",
       "      <td>-0.506595</td>\n",
       "      <td>hyper_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.847516</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.854972</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>-0.003511</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.839990</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.850672</td>\n",
       "      <td>0.024715</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.844341</td>\n",
       "      <td>0.025441</td>\n",
       "      <td>-0.003358</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.026446</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.840225</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.846406</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.849302</td>\n",
       "      <td>0.025671</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.847196</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>-0.003672</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.853492</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.856794</td>\n",
       "      <td>0.027017</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.851420</td>\n",
       "      <td>0.027991</td>\n",
       "      <td>-0.004463</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>-0.001137</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.858322</td>\n",
       "      <td>0.025245</td>\n",
       "      <td>-0.003475</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.845876</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>-0.003167</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.846780</td>\n",
       "      <td>0.026288</td>\n",
       "      <td>-0.003114</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.849396</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.858338</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>-0.000659</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.856408</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>-0.003230</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.847871</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>-0.003265</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.858577</td>\n",
       "      <td>0.024185</td>\n",
       "      <td>-0.003183</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.855428</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>-0.003818</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.858574</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.852471</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>exponential_power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>9.883000</td>\n",
       "      <td>9.629311</td>\n",
       "      <td>6.870490</td>\n",
       "      <td>284.047308</td>\n",
       "      <td>697.254420</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9.874000</td>\n",
       "      <td>9.732124</td>\n",
       "      <td>12.524743</td>\n",
       "      <td>310.993175</td>\n",
       "      <td>1171.855983</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>9.797000</td>\n",
       "      <td>10.227791</td>\n",
       "      <td>8.854090</td>\n",
       "      <td>299.039961</td>\n",
       "      <td>876.229821</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>9.938000</td>\n",
       "      <td>9.326156</td>\n",
       "      <td>5.302903</td>\n",
       "      <td>260.930007</td>\n",
       "      <td>488.074686</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>10.043000</td>\n",
       "      <td>9.873151</td>\n",
       "      <td>5.891284</td>\n",
       "      <td>296.884163</td>\n",
       "      <td>877.826125</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>9.968000</td>\n",
       "      <td>9.870976</td>\n",
       "      <td>8.475646</td>\n",
       "      <td>326.088234</td>\n",
       "      <td>980.498561</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>9.968000</td>\n",
       "      <td>10.508976</td>\n",
       "      <td>11.866894</td>\n",
       "      <td>334.176394</td>\n",
       "      <td>1059.008150</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>10.074000</td>\n",
       "      <td>10.068524</td>\n",
       "      <td>9.778382</td>\n",
       "      <td>299.144757</td>\n",
       "      <td>846.714173</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>10.135000</td>\n",
       "      <td>10.108775</td>\n",
       "      <td>12.490486</td>\n",
       "      <td>327.524411</td>\n",
       "      <td>1256.550873</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>9.929000</td>\n",
       "      <td>10.179959</td>\n",
       "      <td>9.009689</td>\n",
       "      <td>296.979823</td>\n",
       "      <td>758.699096</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>10.071000</td>\n",
       "      <td>9.479959</td>\n",
       "      <td>11.257411</td>\n",
       "      <td>293.125139</td>\n",
       "      <td>979.280158</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>10.151000</td>\n",
       "      <td>10.664199</td>\n",
       "      <td>13.658675</td>\n",
       "      <td>380.477714</td>\n",
       "      <td>1824.798770</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>10.026000</td>\n",
       "      <td>10.629324</td>\n",
       "      <td>8.550895</td>\n",
       "      <td>337.813594</td>\n",
       "      <td>969.540561</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>10.040000</td>\n",
       "      <td>10.440400</td>\n",
       "      <td>12.287088</td>\n",
       "      <td>324.335836</td>\n",
       "      <td>987.189558</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>10.015000</td>\n",
       "      <td>9.998775</td>\n",
       "      <td>10.833052</td>\n",
       "      <td>377.567518</td>\n",
       "      <td>2404.252724</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>10.024000</td>\n",
       "      <td>9.873424</td>\n",
       "      <td>8.043100</td>\n",
       "      <td>285.055740</td>\n",
       "      <td>722.339618</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>9.988000</td>\n",
       "      <td>9.171856</td>\n",
       "      <td>6.942189</td>\n",
       "      <td>246.761301</td>\n",
       "      <td>573.023840</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>10.100000</td>\n",
       "      <td>9.932000</td>\n",
       "      <td>13.349400</td>\n",
       "      <td>331.282220</td>\n",
       "      <td>1484.974620</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>10.022000</td>\n",
       "      <td>10.605516</td>\n",
       "      <td>6.114025</td>\n",
       "      <td>339.893167</td>\n",
       "      <td>663.523030</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>10.090000</td>\n",
       "      <td>9.957900</td>\n",
       "      <td>10.090638</td>\n",
       "      <td>342.365351</td>\n",
       "      <td>1382.905651</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>10.066000</td>\n",
       "      <td>10.287644</td>\n",
       "      <td>15.038759</td>\n",
       "      <td>377.032871</td>\n",
       "      <td>1848.330486</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>10.134000</td>\n",
       "      <td>9.740044</td>\n",
       "      <td>11.480096</td>\n",
       "      <td>275.962993</td>\n",
       "      <td>843.143030</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>9.838000</td>\n",
       "      <td>10.307756</td>\n",
       "      <td>7.587821</td>\n",
       "      <td>295.963119</td>\n",
       "      <td>640.735127</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>10.109000</td>\n",
       "      <td>9.953119</td>\n",
       "      <td>8.955035</td>\n",
       "      <td>286.954946</td>\n",
       "      <td>736.675696</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>10.014000</td>\n",
       "      <td>10.581804</td>\n",
       "      <td>13.933561</td>\n",
       "      <td>386.685276</td>\n",
       "      <td>1703.618431</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2            3             4  \\\n",
       "0     0.278477   0.076947   0.039534     0.044959      0.050045   \n",
       "1     0.294094   0.090901   0.069032     0.132611      0.306223   \n",
       "2     0.273634   0.081426   0.043785     0.048736      0.053657   \n",
       "3     0.277206   0.074974   0.037583     0.041791      0.046933   \n",
       "4     0.265108   0.070054   0.036772     0.040880      0.045851   \n",
       "5     0.287305   0.086687   0.052420     0.071863      0.110257   \n",
       "6     0.270158   0.083211   0.061479     0.098035      0.175570   \n",
       "7     0.271438   0.074232   0.041453     0.052457      0.070142   \n",
       "8     0.279658   0.087117   0.066054     0.102184      0.170926   \n",
       "9     0.297224   0.087612   0.055138     0.075090      0.105865   \n",
       "10    0.282413   0.078377   0.038688     0.044002      0.048824   \n",
       "11    0.281632   0.068224   0.029737     0.031820      0.032633   \n",
       "12    0.303073   0.094398   0.054266     0.067330      0.081840   \n",
       "13    0.285709   0.076835   0.041512     0.055282      0.078633   \n",
       "14    0.293362   0.082765   0.042784     0.046954      0.048631   \n",
       "15    0.271413   0.073062   0.033895     0.033430      0.031036   \n",
       "16    0.277423   0.077938   0.038860     0.041798      0.043272   \n",
       "17    0.291878   0.091614   0.056166     0.076286      0.112284   \n",
       "18    0.292739   0.088436   0.055893     0.075453      0.106315   \n",
       "19    0.287753   0.076151   0.035638     0.038538      0.039880   \n",
       "20    0.280747   0.083716   0.054285     0.081420      0.140376   \n",
       "21    0.289409   0.079826   0.041489     0.045969      0.048981   \n",
       "22    0.290112   0.081085   0.042643     0.050522      0.060150   \n",
       "23    0.296659   0.093434   0.066137     0.099226      0.159751   \n",
       "24    0.289576   0.090444   0.053283     0.063077      0.072860   \n",
       "25    0.974669   0.942605   1.695013     6.746629     26.284591   \n",
       "26    1.029327   1.113531   2.959749    19.899957    160.834152   \n",
       "27    0.957717   0.997466   1.877276     7.313499     28.181585   \n",
       "28    0.970221   0.918433   1.611387     6.271201     24.650097   \n",
       "29    0.927878   0.858156   1.576605     6.134503     24.082002   \n",
       "30    1.005568   1.061911   2.247510    10.783912     57.909049   \n",
       "31    0.945553   1.019337   2.635931    14.711318     92.212898   \n",
       "32    0.950032   0.909347   1.777301     7.871832     36.839676   \n",
       "33    0.978803   1.067185   2.832069    15.333930     89.773692   \n",
       "34    1.040283   1.073242   2.364030    11.268170     55.602299   \n",
       "35    0.988447   0.960113   1.658757     6.603118     25.643394   \n",
       "36    0.985712   0.835746   1.274990     4.774917     17.139402   \n",
       "37    1.060756   1.156375   2.326652    10.103728     42.983892   \n",
       "38    0.999981   0.941229   1.779812     8.295732     41.299443   \n",
       "39    1.026769   1.013868   1.834373     7.045969     25.542083   \n",
       "40    0.949944   0.895004   1.453244     5.016631     16.300536   \n",
       "41    0.970980   0.954746   1.666106     6.272258     22.727139   \n",
       "42    1.021574   1.122276   2.408134    11.447675     58.973541   \n",
       "43    1.024586   1.083343   2.396400    11.322599     55.838803   \n",
       "44    1.007134   0.932847   1.527965     5.783078     20.945915   \n",
       "45    0.982615   1.025521   2.327461    12.218086     73.728175   \n",
       "46    1.012932   0.977864   1.778843     6.898218     25.725767   \n",
       "47    1.015390   0.993290   1.828333     7.581510     31.591863   \n",
       "48    1.038308   1.144565   2.835612    14.890162     83.903993   \n",
       "49    1.013516   1.107944   2.284496     9.465561     38.267282   \n",
       "50    1.531265   3.136374  19.029185   184.498703   1916.780787   \n",
       "51    1.596649   3.373854  18.989939   180.824257   1888.931844   \n",
       "52    1.605864   4.400015  60.698859  1716.165665  56721.369871   \n",
       "53    1.575350   4.175707  46.405978  1029.942996  27319.260786   \n",
       "54    1.574421   3.727588  27.487909   347.650632   5025.101467   \n",
       "55    1.601411   4.632585  53.835993   995.655436  20118.320040   \n",
       "56    1.714511   4.884108  45.757692   716.122340  12555.631380   \n",
       "57    1.738949   5.382786  67.721896  1621.835290  47003.940030   \n",
       "58    1.734348   4.988502  75.833386  2357.049707  85180.100002   \n",
       "59    1.670441   4.715232  66.496558  1623.891831  44502.978053   \n",
       "60    1.639070   3.748684  27.685409   355.760489   5037.097591   \n",
       "61    1.654432   3.688545  18.740236   154.228645   1303.854821   \n",
       "62    1.657732   4.268721  33.188316   469.999742   8062.727845   \n",
       "63    1.589619   3.994325  45.075532  1037.232649  28539.720619   \n",
       "64    1.654485   5.107409  63.084131  1314.861141  31380.434438   \n",
       "65    1.666209   5.966266  89.396587  2160.488402  58525.102877   \n",
       "66    1.674035   4.282708  32.377782   391.455121   5141.682996   \n",
       "67    1.597441   3.172705  18.328881   200.084300   2522.157878   \n",
       "68    1.693633   4.647290  48.139257   968.165487  23419.823642   \n",
       "69    1.505290   2.999431  19.294948   215.857402   2677.618610   \n",
       "70    1.751610   5.430262  47.804928   658.631324   9903.366135   \n",
       "71    1.592525   3.755191  25.118665   299.200480   4186.720006   \n",
       "72    1.589577   4.257870  59.878736  1661.876101  53787.767706   \n",
       "73    1.710450   4.661754  39.346754   580.409580   9913.412009   \n",
       "74    1.472298   2.497811  14.727903   177.173520   2516.658829   \n",
       "75    0.508290   0.129629  -0.001551     0.024219     -0.000581   \n",
       "76    0.499712   0.121832   0.000321     0.022717      0.000141   \n",
       "77    0.495582   0.130833   0.001741     0.024690      0.000617   \n",
       "78    0.511882   0.123728  -0.001812     0.023126     -0.000720   \n",
       "79    0.505809   0.127109  -0.001205     0.024188     -0.000470   \n",
       "80    0.492339   0.126515   0.001274     0.024030      0.000582   \n",
       "81    0.515454   0.130078  -0.001700     0.024711     -0.000802   \n",
       "82    0.518054   0.120324  -0.002152     0.022480     -0.001071   \n",
       "83    0.495548   0.123001   0.000589     0.023095      0.000304   \n",
       "84    0.492308   0.128227   0.001289     0.024229      0.000578   \n",
       "85    0.513482   0.123430  -0.001998     0.023198     -0.000849   \n",
       "86    0.523421   0.123969  -0.003378     0.023182     -0.001466   \n",
       "87    0.504862   0.130860  -0.000492     0.024663     -0.000227   \n",
       "88    0.503063   0.125816  -0.000202     0.023814     -0.000090   \n",
       "89    0.501392   0.121268  -0.001038     0.022390     -0.000361   \n",
       "90    0.497111   0.120115   0.000455     0.021990      0.000200   \n",
       "91    0.504181   0.122514  -0.000604     0.022734     -0.000265   \n",
       "92    0.497931   0.123217   0.000780     0.023049      0.000259   \n",
       "93    0.529533   0.125682  -0.005112     0.023679     -0.002126   \n",
       "94    0.504727   0.126001  -0.000352     0.023805     -0.000259   \n",
       "95    0.502480   0.121207  -0.000273     0.022377     -0.000143   \n",
       "96    0.513662   0.126634  -0.002427     0.024152     -0.001026   \n",
       "97    0.505320   0.124370  -0.001240     0.023665     -0.000520   \n",
       "98    0.497222   0.120658   0.001627     0.022619      0.000609   \n",
       "99    0.512487   0.131533  -0.001693     0.024777     -0.000742   \n",
       "100   0.439291   0.044111   0.002476     0.004547      0.000640   \n",
       "101   0.449721   0.045178   0.002427     0.004676      0.000600   \n",
       "102   0.431187   0.045752   0.003384     0.005013      0.000887   \n",
       "103   0.440386   0.042461   0.002825     0.004325      0.000679   \n",
       "104   0.431497   0.040952   0.002680     0.004231      0.000690   \n",
       "105   0.443633   0.045272   0.002993     0.004832      0.000758   \n",
       "106   0.429884   0.043785   0.002895     0.004657      0.000794   \n",
       "107   0.435286   0.042357   0.002693     0.004239      0.000683   \n",
       "108   0.439057   0.042577   0.002842     0.004556      0.000784   \n",
       "109   0.453618   0.044235   0.001938     0.004739      0.000518   \n",
       "110   0.441032   0.045633   0.002306     0.004726      0.000599   \n",
       "111   0.446689   0.042243   0.001150     0.004242      0.000325   \n",
       "112   0.453911   0.047349   0.002681     0.005045      0.000698   \n",
       "113   0.446131   0.044291   0.001546     0.004528      0.000431   \n",
       "114   0.451895   0.043672   0.002533     0.004595      0.000612   \n",
       "115   0.434921   0.042793   0.003113     0.004436      0.000737   \n",
       "116   0.437788   0.044246   0.003014     0.004594      0.000756   \n",
       "117   0.444495   0.047147   0.002977     0.005165      0.000770   \n",
       "118   0.450446   0.043327   0.003072     0.004483      0.000736   \n",
       "119   0.449327   0.043242   0.002199     0.004350      0.000520   \n",
       "120   0.439414   0.044369   0.002826     0.004647      0.000731   \n",
       "121   0.450530   0.042344   0.002584     0.004353      0.000625   \n",
       "122   0.449246   0.044003   0.002354     0.004577      0.000566   \n",
       "123   0.451891   0.044086   0.002786     0.004618      0.000726   \n",
       "124   0.444509   0.045233   0.003549     0.004861      0.000907   \n",
       "125  -0.014557   0.879765  -0.002557     2.393398     -0.137235   \n",
       "126  -0.011092   0.989576  -0.058273     2.786129     -0.498211   \n",
       "127  -0.021054   1.008537  -0.060422     2.985959     -0.197113   \n",
       "128  -0.057498   1.031559   0.024978     2.963175      0.312670   \n",
       "129  -0.039038   1.003398  -0.042553     2.978564     -0.305131   \n",
       "130  -0.004476   0.908281   0.104680     2.574936      0.897907   \n",
       "131   0.023742   1.041997  -0.034840     3.293245     -0.487705   \n",
       "132   0.049386   0.993579   0.029410     3.040081      0.260338   \n",
       "133   0.077557   0.960866  -0.066598     2.799230     -0.329110   \n",
       "134   0.048050   0.960096  -0.158853     2.903149     -0.683796   \n",
       "135   0.029131   0.943824  -0.026802     2.611996     -0.174299   \n",
       "136  -0.016721   1.102892  -0.145662     3.517307     -1.812149   \n",
       "137  -0.002597   1.006196   0.094467     2.851681      0.489468   \n",
       "138  -0.012805   0.965703  -0.044563     2.777876     -0.164021   \n",
       "139  -0.021255   1.069079  -0.097764     3.521419     -0.651782   \n",
       "140  -0.020236   1.020565   0.088318     3.284959      0.732796   \n",
       "141   0.013738   1.023779  -0.059434     3.149239     -0.605717   \n",
       "142   0.001566   0.996032  -0.200003     3.079174     -2.318946   \n",
       "143   0.016752   1.037377  -0.017003     3.045774      0.051260   \n",
       "144  -0.051274   0.966770  -0.154680     2.840479     -1.288667   \n",
       "145   0.012444   1.075475   0.123754     3.309352      0.905070   \n",
       "146  -0.040144   1.024431  -0.001404     3.057967     -0.355783   \n",
       "147  -0.008138   0.950276  -0.035908     2.714124     -0.205872   \n",
       "148   0.025850   1.013246   0.083868     2.888145      0.590343   \n",
       "149  -0.032585   0.882453  -0.146300     2.440372     -1.724633   \n",
       "150   4.185000   1.130775  -0.130912     3.536499     -1.043270   \n",
       "151   4.142000   1.155836  -0.071249     3.872225     -0.856066   \n",
       "152   4.214000   1.082204   0.085425     3.107416      0.463436   \n",
       "153   4.197000   1.094191  -0.259312     3.877045     -3.215205   \n",
       "154   4.166000   1.250444  -0.005295     4.362013     -0.390337   \n",
       "155   4.267000   1.145711   0.026251     3.621822      0.113720   \n",
       "156   4.225000   1.100375  -0.187144     3.466628     -1.876131   \n",
       "157   4.175000   1.182375  -0.115106     4.003375     -0.836234   \n",
       "158   4.175000   1.232375  -0.105356     3.893363     -1.045639   \n",
       "159   4.244000   1.070464  -0.170106     3.406092     -1.446527   \n",
       "160   4.206000   1.145564  -0.126700     3.662921     -0.853557   \n",
       "161   4.214000   1.132204  -0.162675     3.788050     -1.716124   \n",
       "162   4.207000   1.126151  -0.033210     3.521135     -0.583411   \n",
       "163   4.200000   1.132000  -0.097200     3.484480     -0.546480   \n",
       "164   4.154000   1.058284  -0.032579     3.194917     -0.327097   \n",
       "165   4.206000   1.133564  -0.203284     3.789082     -2.209954   \n",
       "166   4.168000   1.221776   0.015483     4.247898      0.077330   \n",
       "167   4.144000   1.141264   0.145988     3.563489      1.323876   \n",
       "168   4.155000   1.214975  -0.125687     4.261210     -1.962575   \n",
       "169   4.237000   1.178831  -0.056461     3.588087     -0.510844   \n",
       "170   4.194000   1.166364  -0.084125     3.812481     -0.677881   \n",
       "171   4.101000   1.100799  -0.041572     3.556316     -1.222051   \n",
       "172   4.219000   1.155039   0.013636     4.264374      0.281148   \n",
       "173   4.221000   1.176159  -0.041587     3.914709     -0.611922   \n",
       "174   4.239000   1.103879  -0.020133     3.594656     -0.506595   \n",
       "175   0.847516   0.026798  -0.003421     0.002344     -0.000716   \n",
       "176   0.854972   0.026470  -0.003511     0.002451     -0.000818   \n",
       "177   0.839990   0.028286  -0.003440     0.002536     -0.000760   \n",
       "178   0.850672   0.024715  -0.002839     0.001995     -0.000581   \n",
       "179   0.844341   0.025441  -0.003358     0.002325     -0.000765   \n",
       "180   0.850769   0.026446  -0.003129     0.002220     -0.000640   \n",
       "181   0.840225   0.027728  -0.003631     0.002630     -0.000861   \n",
       "182   0.846406   0.025275  -0.002852     0.002045     -0.000614   \n",
       "183   0.849302   0.025671  -0.003287     0.002340     -0.000766   \n",
       "184   0.858156   0.026848  -0.004316     0.002869     -0.001089   \n",
       "185   0.847196   0.027977  -0.003672     0.002500     -0.000787   \n",
       "186   0.853492   0.026875  -0.004390     0.002731     -0.001008   \n",
       "187   0.856794   0.027017  -0.003342     0.002379     -0.000758   \n",
       "188   0.851420   0.027991  -0.004463     0.002955     -0.001137   \n",
       "189   0.858322   0.025245  -0.003475     0.002372     -0.000821   \n",
       "190   0.845876   0.025639  -0.003167     0.002316     -0.000773   \n",
       "191   0.846780   0.026288  -0.003114     0.002299     -0.000749   \n",
       "192   0.849396   0.028148  -0.003623     0.002568     -0.000786   \n",
       "193   0.858338   0.023966  -0.002734     0.002031     -0.000659   \n",
       "194   0.856408   0.025096  -0.003230     0.002135     -0.000663   \n",
       "195   0.847871   0.026560  -0.003265     0.002333     -0.000728   \n",
       "196   0.858577   0.024185  -0.003183     0.002219     -0.000781   \n",
       "197   0.855428   0.026168  -0.003818     0.002626     -0.000966   \n",
       "198   0.858574   0.024631  -0.002769     0.001961     -0.000555   \n",
       "199   0.852471   0.025164  -0.002419     0.001846     -0.000446   \n",
       "200   9.883000   9.629311   6.870490   284.047308    697.254420   \n",
       "201   9.874000   9.732124  12.524743   310.993175   1171.855983   \n",
       "202   9.797000  10.227791   8.854090   299.039961    876.229821   \n",
       "203   9.938000   9.326156   5.302903   260.930007    488.074686   \n",
       "204  10.043000   9.873151   5.891284   296.884163    877.826125   \n",
       "205   9.968000   9.870976   8.475646   326.088234    980.498561   \n",
       "206   9.968000  10.508976  11.866894   334.176394   1059.008150   \n",
       "207  10.074000  10.068524   9.778382   299.144757    846.714173   \n",
       "208  10.135000  10.108775  12.490486   327.524411   1256.550873   \n",
       "209   9.929000  10.179959   9.009689   296.979823    758.699096   \n",
       "210  10.071000   9.479959  11.257411   293.125139    979.280158   \n",
       "211  10.151000  10.664199  13.658675   380.477714   1824.798770   \n",
       "212  10.026000  10.629324   8.550895   337.813594    969.540561   \n",
       "213  10.040000  10.440400  12.287088   324.335836    987.189558   \n",
       "214  10.015000   9.998775  10.833052   377.567518   2404.252724   \n",
       "215  10.024000   9.873424   8.043100   285.055740    722.339618   \n",
       "216   9.988000   9.171856   6.942189   246.761301    573.023840   \n",
       "217  10.100000   9.932000  13.349400   331.282220   1484.974620   \n",
       "218  10.022000  10.605516   6.114025   339.893167    663.523030   \n",
       "219  10.090000   9.957900  10.090638   342.365351   1382.905651   \n",
       "220  10.066000  10.287644  15.038759   377.032871   1848.330486   \n",
       "221  10.134000   9.740044  11.480096   275.962993    843.143030   \n",
       "222   9.838000  10.307756   7.587821   295.963119    640.735127   \n",
       "223  10.109000   9.953119   8.955035   286.954946    736.675696   \n",
       "224  10.014000  10.581804  13.933561   386.685276   1703.618431   \n",
       "\n",
       "                  dist  \n",
       "0          exponential  \n",
       "1          exponential  \n",
       "2          exponential  \n",
       "3          exponential  \n",
       "4          exponential  \n",
       "5          exponential  \n",
       "6          exponential  \n",
       "7          exponential  \n",
       "8          exponential  \n",
       "9          exponential  \n",
       "10         exponential  \n",
       "11         exponential  \n",
       "12         exponential  \n",
       "13         exponential  \n",
       "14         exponential  \n",
       "15         exponential  \n",
       "16         exponential  \n",
       "17         exponential  \n",
       "18         exponential  \n",
       "19         exponential  \n",
       "20         exponential  \n",
       "21         exponential  \n",
       "22         exponential  \n",
       "23         exponential  \n",
       "24         exponential  \n",
       "25               gamma  \n",
       "26               gamma  \n",
       "27               gamma  \n",
       "28               gamma  \n",
       "29               gamma  \n",
       "30               gamma  \n",
       "31               gamma  \n",
       "32               gamma  \n",
       "33               gamma  \n",
       "34               gamma  \n",
       "35               gamma  \n",
       "36               gamma  \n",
       "37               gamma  \n",
       "38               gamma  \n",
       "39               gamma  \n",
       "40               gamma  \n",
       "41               gamma  \n",
       "42               gamma  \n",
       "43               gamma  \n",
       "44               gamma  \n",
       "45               gamma  \n",
       "46               gamma  \n",
       "47               gamma  \n",
       "48               gamma  \n",
       "49               gamma  \n",
       "50           lognormal  \n",
       "51           lognormal  \n",
       "52           lognormal  \n",
       "53           lognormal  \n",
       "54           lognormal  \n",
       "55           lognormal  \n",
       "56           lognormal  \n",
       "57           lognormal  \n",
       "58           lognormal  \n",
       "59           lognormal  \n",
       "60           lognormal  \n",
       "61           lognormal  \n",
       "62           lognormal  \n",
       "63           lognormal  \n",
       "64           lognormal  \n",
       "65           lognormal  \n",
       "66           lognormal  \n",
       "67           lognormal  \n",
       "68           lognormal  \n",
       "69           lognormal  \n",
       "70           lognormal  \n",
       "71           lognormal  \n",
       "72           lognormal  \n",
       "73           lognormal  \n",
       "74           lognormal  \n",
       "75                beta  \n",
       "76                beta  \n",
       "77                beta  \n",
       "78                beta  \n",
       "79                beta  \n",
       "80                beta  \n",
       "81                beta  \n",
       "82                beta  \n",
       "83                beta  \n",
       "84                beta  \n",
       "85                beta  \n",
       "86                beta  \n",
       "87                beta  \n",
       "88                beta  \n",
       "89                beta  \n",
       "90                beta  \n",
       "91                beta  \n",
       "92                beta  \n",
       "93                beta  \n",
       "94                beta  \n",
       "95                beta  \n",
       "96                beta  \n",
       "97                beta  \n",
       "98                beta  \n",
       "99                beta  \n",
       "100          trapezoid  \n",
       "101          trapezoid  \n",
       "102          trapezoid  \n",
       "103          trapezoid  \n",
       "104          trapezoid  \n",
       "105          trapezoid  \n",
       "106          trapezoid  \n",
       "107          trapezoid  \n",
       "108          trapezoid  \n",
       "109          trapezoid  \n",
       "110          trapezoid  \n",
       "111          trapezoid  \n",
       "112          trapezoid  \n",
       "113          trapezoid  \n",
       "114          trapezoid  \n",
       "115          trapezoid  \n",
       "116          trapezoid  \n",
       "117          trapezoid  \n",
       "118          trapezoid  \n",
       "119          trapezoid  \n",
       "120          trapezoid  \n",
       "121          trapezoid  \n",
       "122          trapezoid  \n",
       "123          trapezoid  \n",
       "124          trapezoid  \n",
       "125             normal  \n",
       "126             normal  \n",
       "127             normal  \n",
       "128             normal  \n",
       "129             normal  \n",
       "130             normal  \n",
       "131             normal  \n",
       "132             normal  \n",
       "133             normal  \n",
       "134             normal  \n",
       "135             normal  \n",
       "136             normal  \n",
       "137             normal  \n",
       "138             normal  \n",
       "139             normal  \n",
       "140             normal  \n",
       "141             normal  \n",
       "142             normal  \n",
       "143             normal  \n",
       "144             normal  \n",
       "145             normal  \n",
       "146             normal  \n",
       "147             normal  \n",
       "148             normal  \n",
       "149             normal  \n",
       "150    hyper_geometric  \n",
       "151    hyper_geometric  \n",
       "152    hyper_geometric  \n",
       "153    hyper_geometric  \n",
       "154    hyper_geometric  \n",
       "155    hyper_geometric  \n",
       "156    hyper_geometric  \n",
       "157    hyper_geometric  \n",
       "158    hyper_geometric  \n",
       "159    hyper_geometric  \n",
       "160    hyper_geometric  \n",
       "161    hyper_geometric  \n",
       "162    hyper_geometric  \n",
       "163    hyper_geometric  \n",
       "164    hyper_geometric  \n",
       "165    hyper_geometric  \n",
       "166    hyper_geometric  \n",
       "167    hyper_geometric  \n",
       "168    hyper_geometric  \n",
       "169    hyper_geometric  \n",
       "170    hyper_geometric  \n",
       "171    hyper_geometric  \n",
       "172    hyper_geometric  \n",
       "173    hyper_geometric  \n",
       "174    hyper_geometric  \n",
       "175  exponential_power  \n",
       "176  exponential_power  \n",
       "177  exponential_power  \n",
       "178  exponential_power  \n",
       "179  exponential_power  \n",
       "180  exponential_power  \n",
       "181  exponential_power  \n",
       "182  exponential_power  \n",
       "183  exponential_power  \n",
       "184  exponential_power  \n",
       "185  exponential_power  \n",
       "186  exponential_power  \n",
       "187  exponential_power  \n",
       "188  exponential_power  \n",
       "189  exponential_power  \n",
       "190  exponential_power  \n",
       "191  exponential_power  \n",
       "192  exponential_power  \n",
       "193  exponential_power  \n",
       "194  exponential_power  \n",
       "195  exponential_power  \n",
       "196  exponential_power  \n",
       "197  exponential_power  \n",
       "198  exponential_power  \n",
       "199  exponential_power  \n",
       "200            poisson  \n",
       "201            poisson  \n",
       "202            poisson  \n",
       "203            poisson  \n",
       "204            poisson  \n",
       "205            poisson  \n",
       "206            poisson  \n",
       "207            poisson  \n",
       "208            poisson  \n",
       "209            poisson  \n",
       "210            poisson  \n",
       "211            poisson  \n",
       "212            poisson  \n",
       "213            poisson  \n",
       "214            poisson  \n",
       "215            poisson  \n",
       "216            poisson  \n",
       "217            poisson  \n",
       "218            poisson  \n",
       "219            poisson  \n",
       "220            poisson  \n",
       "221            poisson  \n",
       "222            poisson  \n",
       "223            poisson  \n",
       "224            poisson  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa1f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9.263621e+00\n",
       "1    9.846756e+00\n",
       "2    2.238705e+02\n",
       "3    1.241443e+05\n",
       "4    1.052515e+08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.var(numeric_only=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
